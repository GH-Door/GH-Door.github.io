---
layout: post
title: "[빅분기] 필기 Chapter 02. 데이터 분석 계획"
description: "[빅데이터분석기사] 필기 'Chapter 02. 데이터 분석 계획' 내용을 정리했습니다."
author: "DoorNote"
date: 2025-03-14 10:00:00 +0900
permalink: /big-data-2/
categories:
    - 자격증
    - 빅데이터분석기사
tags: ['[빅분기]-필기', PART 01. 빅데이터 분석 기획]
comments: true
pin: false # 고정핀
math: true
mermaid: true
image: /assets/img/빅데이터분석기사.png
---

## 들어가며

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**빅데이터분석기사 필기 시험**을 준비하며 공부한 내용을 **Chapter** 별 핵심 내용 기준으로 정리한 내용입니다.<br>
교재는 [이기적-빅데이터분석기사 필기-2024](https://search.shopping.naver.com/book/catalog/41869053620?cat_id=50010601&frm=PBOKPRO&query=%EC%9D%B4%EA%B8%B0%EC%A0%81+%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC+%ED%95%84%EA%B8%B0&NaPm=ct%3Dm88q4ot4%7Cci%3D23875283d14200743013ebc63ca27206ecd57363%7Ctr%3Dboknx%7Csn%3D95694%7Chk%3Dd90241b163c19c2f3cce4b072ef86e71d42f9d26)로 공부했습니다.   
</blockquote>

<br>
<br>

## 01. 분석 방안 수립

---

### 1. 데이터 분석

#### **1-1) 데이터 분석의 현황**

- **대다수의 기업들은** 빅데이터가 갖고있는 무한한 비즈니스 잠재력을 규명하는 **초기 프로젝트에 머무르고 있다.**<br>
- 빅데이터를 활용하기 위한 **장애물은 비용보다 데이터 분석**을 수행하기 위한 **분석적 방법과 성과에 대한 이해**의 부족이다.

<br>

#### **1-2) 데이터 분석의 지향점**

1. 전략적 통찰이 없는 데이터 분석 배제
    - 분석은 경쟁의 본질에 영향을 미치고 기업의 경쟁전략을 이끌어 가므로, 경쟁의 본질을 제대로 바라보지 못한 분석은 불필요한 결과를 만들어 낸다.

2. 일차원적인 데이터 분석 지양
    - **대부분의 기업들은 업계 내부의 문제에만 중점을 두고 있으며**, 주로 부서 단위로 관리되기에 전체 비즈니스 관점의 핵심적인 역할을 기대하기 어렵다.

3. 전략 도출을 위한 가치 기반 데이터 분석 지향
    - **가치 기반 데이터 분석**을 통해 해당 사업의 중요한 기회를 발굴하고, 경영진의 지원을 얻어낼 수 있으며 **이를 통해 강력한 모멘텀을 형성할 수 있다.**

<br>

#### **1-3) 데이터 분석 시 고려사항**

- **데이터 분석은 규모가 아니라 어떤 시각과 통찰을 얻을 수 있는가의 문제**이다. 
- 전략과 비즈니스의 핵심 가치에 집중하고 관련된 **분석 평가지표**를 개발하여 시장과 고객 변화에 효과적으로 대응하는 것이 중요

<br>
<br>

### 2. 데이터 분석 기획

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**어떠한 목표(What)**를 달성하기 **위해(Why)** 어떠한 데이터를 가지고 **어떤 방식으로(How)** 수행할 것인가에 대한 일련의 계획을 수립
</blockquote>

#### **2-1) 분석 기획의 특징**

- 분석 주제와 방법에 대한 특성상 **4가지 유형을 넘나들며 분석을 하고 결과를 도출하는 과정을 반복**
- **데이터 분석 주제 유형과 분석 과제 도출 방법**
    1. **Optimization**은 분석 주제와 방법을 모두 알고 있을 때 가능하다.
    2. **Insight**는 분석 방법을 알고 있을 때 가능하다.
    3. **Solution**은 분석 주제는 알지만 방법을 알지 못한 경우에도 찾을 수 있다.
    4. **Discovery**는 분석 주제와 방법 모두 모르고 있더라도 가능하다.

<br>

- **✅ 목표 시점에 따른 분류**

| **단기적 접근** 방식 | - 당면한 과제를 빠르게 해결하기 위한 목적<br>- 명확한 해결을 위해 Quick-Win 방식으로 분석 |
| **중장기적 접근** 방식 | - 지속적인 분석 문화를 내재화하기 위한 목적<br>- 전자적으로 장기적 관점에서 과제를 도출하여 수행 |
| **혼합** 방식 | - 마스터 플랜을 수립하고 장기적 관점에서 접근하는 것이 바람직<br>- 분석의 가치를 증명하고 이해관계자들의 동의를 얻기 위해 과제를 빠르게 해결하여 그 가치를 조기에 체험 |

<br>

#### **2-2) 분석 기획 시 필요역량**

1. 분석 기획을 위한 기본적인 소양
    - **도메인 지식**
    - **정보 기술**
    - **수학 및 통계학적 지식**

2. 프로젝트 관리 역량과 리더십
    - 분석 기획 시 기본적인 **3가지 소양**과 함께 프로젝트 관리 역량과 분석 프로젝트를 잘 이끌어 갈 리더십이 중요

<br>

#### **2-3) 분석 기획 시 고려사항**

1. **사용 가능한 데이터 확인**
    - 데이터 확보 가능 여부, 데이터의 유형 등을 미리 확인
    - 데이터의 유형에 따라 적용 가능한 솔루션이나 분석 방법론이 달라진다.

2. **적합한 사례 탐색**
    - 유사 분석 시나리오나 솔루션이 있다면 이를 최대한 활용하는 것이 유리

3. **분석 수행 시 발생 가능한 요소 고려**
    - **비용 상승**을 충분히 고려
    - 사용자가 쉽게 이해할 수 있도록 **시각화** 등을 고려
    - 분석 결과를 **실제 환경에서도 성능에 문제없이 적용할 수 있도록** 충분히 고려
    - **일회성 분석으로 그치지 않고** 조직의 역량으로 내재화될 수 있도록 계속적인 교육과 활용방안 등의 변화 관리방안을 수립

**데이터 분석 유형**

| **설명** 분석 | - 가장 기본이 되는 분석으로 데이터를 요약, 집계하여 결과를 도출<br>- 과거 또는 현재 발생한 사실 그 자체를 설명 |
| **예측** 분석 | - 미래의 불확실한 사실을 사전에 예측<br>- 알려지지 않은 결과의 가능성을 파악하기 위해 사용하는 분석 방법 |
| **진단** 분석 | - 데이터 간의 인과 관계 또는 상관 관계를 파악<br>- 특정 결과가 발생한 원인을 밝히기 위해 분석을 수행 |
| **처방** 분석 | - 예측되는 상황을 위해 무엇을 하면 좋을 지 대안을 제시<br>- 대안 도출과 의사 결정은 물론 일부 실행까지 진행하는 분석방법 |

<br>
<br>

### 3. 분석 마스터 플랜과 로드맵 설정

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**분석 마스터 플랜**은 분석 과제를 수행함에 있어 그 과제의 목적이나 목표에 따라 전체적인 방향성을 제시하는 기본 계획이다.
</blockquote>

#### **3-1) 데이터 분석 프로젝트의 우선순위 평가 기준**

- 기존 IT 프로젝트와는 다른 기준으로 우선순위 평가 기준을 정의해야한다.
- 과제를 수행하고자 하는 기업이 처한 상황에 따라 그 기준이 달라질 수 있다.
- **빅데이터의 특징을 고려한 ROI 요소 4V**

**투자비용 요소 3V**

| 특징 | 내용 |
|:---:|:---|
| 데이터 크기<br>(Volume) | - 데이터 규모<br>- 데이터 양 |
| 데이터 형태<br>(Variety) | - 데이터 종류<br>- 데이터 유형 |
| 데이터 속도<br>(Velocity) | - 데이터 생성속도<br>- 데이터 처리속도 |

<br>

**비즈니스 효과**

| 특징 | 내용 |
|:---:|:---|
| 새로운 가치<br>(Value) | - 분석 결과 활용을 통한 획득 가치<br>- 비즈니스 실행을 통한 획득 가치 |

<br>

#### **3-2) 분석 ROI 요소를 고려한 과제 우선순위 평가기준**

| 평가관점 | 평가요소 | 내용 | ROI 요소 |
|:---:|:---|:---|:---:|
| 시급성<br>(중요) | - 전략적 중요도<br>- 목표가치(**KPI**) | - 현재의 관점에 전략적 가치를 둘 것인지 판단<br>- 중장기적 관점에 전략적 가치를 둘 것인지 판단 | 비즈니스 효과 |
| 난이도 | - 데이터 획득 비용<br>- 데이터 가공 비용<br>- 데이터 저장 비용<br>- 분석 적용 비용 | - 비용과 범위 측면에서 적용하기 쉬운 과제인지 판단<br>- 과제 범위를 **PoC** 또는 처음부터 크게 할 것인지 판단 | 투자비용 요소 |

<br>

- **KPI**: 핵심성과지표
- **PoC**: 개념증명, 원리 또는 실현 가능성을 입증하기 위하여 어떤 방법이나 아이디어에 대한 실현성을 보여주는 일

<br>

#### **3-3) 분석 로드맵 설정**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
분석 로드맵은 **마스터 플랜**에서 정의한 목표를 기반으로 분석 과제를 수행하기 위해 필요한 기준 등을 담아 만든 **종합적인** 계획
</blockquote>

- 최종적인 실행 우선순위를 결정하여 단계적 구현 로드맵을 수립
- 단계별로 추진하고자 하는 모굪를 명확하게 정의
- 추진 과제별 선행 관계를 고려하여 단계별 추진 내용을 정렬

<br>

**분석 로드맵 수립 절차**

<img src="/assets/img/load-map.png" width="100%">

<br>

**세부적인 일정 계획 수립**

- 반복적인 정련과정을 통해 프로젝트의 완성도를 높여 나감
- 데이터 수집 및 확보와 분석 데이터 준비 단계는 **순차적으로** 진행하고 모델링 단계는 **반복적으로** 수행
- 주로 **순차형과** **반복형을** 혼합하여 수행

<br>
<br>

### 4. 분석 문제 정의

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
분석 과제는 해결해야 할 다양한 문제들을 데이터 분석 문제로 변환하여 분석 프로젝트로 수행할 수 있는 과제정의서 형태로 도출한다.
</blockquote>

#### **4-1) 분석 문제 정의 개요**

1. 대표적인 분석 과제 도출 방법
    - 문제가 먼저 주어지고 이에 대한 해법을 찾아가는 **하양식 접근 방식**과
    - 데이터를 기반으로 문제의 재정의 및 해결방안을 탐색하는**상향식 접근 방식**이 있다.

2. 최적의 의사결정을 위한 혼합 방식
    - 동적인 환경에서 **발산과 수렴을 반복적으로** 수행하며 **상호 보완**을 통해 분석의 가치를 **극대화할 수 있다.**
    - 상향식 접근 방식의 발산 단계: 가능한 옵션을 도출
    - 하양식 접근 방식의 수렴 단계: 도출된 옵션을 분석하고 검증

<img src="/assets/img/data-topic-types.png" width="80%">

<br>

#### **4-2) 하양식 접근 방식**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**하양식 접근 방식**은 문제가 주어지고 이에 대한 해법을 찾기 위하여 각 과정이 단계화 되어 수행하는 방식이다.
</blockquote>

<img src="/assets/img/top-down.png" width="100%">

<br>

**하양식 접근 방식의 구성**

| 단계 | 내용 |
|:----:|:----|
| 문제 탐색 | 현황 분석, 인식된 문제점, 전략에서 기회나 문제를 탐색 |
| 문제 정의 | 해당 현실 문제를 데이터 관점의 문제로 정의 |
| 해결방안 탐색 | 데이터 관점의 문제를 해결하기 위한 방안을 탐색 |
| 타당성 평가 | 데이터 분석의 타당성을 평가 |

<br>

#### **4-3) 상향식 접근 방식**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
문제의 정의 자체가 어려운 경우 **데이터를 기반으로** 문제의 재정의 및 해결방안을 **탐색(EDA)하고** 이를 지속적으로 개선하는 방식이다.
</blockquote>

1. 상향식 접근 방식의 특징
    - 다량의 데이터 분석을 통해 **왜(Why) 그러한 일이 발생하는지 역으로 추적하면서 문제를 도출하거나** 재정의할 수 있는 방식
    - 데이터를 활용하여 **생각지도 못했던 인사이트 도출 및 시행착오를 통한 개선이 가능**

2. 상향식 접근 방식의 등장배경
    - **기존 하양식 접근 방식의 한계를 극복**하기 위해 등장
    - 하양식 접근 방식은 **솔루션 도출은 유효하지만 새로운 문제 탐색은 어렵다.**
    - 하양식 접근 방식은 **복잡하고 다양한 환경에서 발생한 문제에는 부적합하다.**

3. 상향식 접근기반 전통적 분석 사고 극복방안
    1. **비지도 학습 방법에 의한 수행**
        - 목표값을 사전에 학습하거나 정의하지 않고 데이터 자체만을 가지고 결과를 도출
        - 새로운 데이터 유형의 인사이트를 도출하기에 적합
        - 데이터 마이닝의 연관규칙분석, 군집분석, 기술통계 및 프로파일링 등이 대표적
    2. **빅데이터 환경에서의 분석**
        - 인과관계에서 상관관계 분석으로 이동했다.
        - 통계적 분석환경에서는 인과관계 분석을 위해 가설을 설정하고 이를 검증하기 위해 모집단으로부텅 표본을 추출하여 가설검증을 진행

4. ✅ 상향식 접근 방식의 **문제 해결 방법**
    - **프로토타이핑 접근법**: 일단 먼저 분석을 시도해 보고 그 결과를 확인하면서 반복적으로 개선해 나가는 방식
    - **시행착오**를 통하여 문제 해결을 시도하는 방식이다.
    - 사용자가 **요구사항이나** 데이터를 정확히 정의하기 어렵고 **원천 데이터도 명확하지 않을 때 주로 사용**

<br>
<br>

### 5. 데이터 분석 방안

#### **5-1) 분석 방법론**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
데이터 분석 시 품질확보를 위하여 단계별로 수행해야 하는 활동, 작업, 산출물을 정의한다.
</blockquote>

1. 분석 방법론의 구성요건
    - 상세한 절차
    - 방법
    - 도구와 기법
    - 템플릿과 산출물
    - 어느 정도의 지식만 있으면 활용 가능한 수준의 난이도

2. **분석 방법론의 생성과정(선순환 과정)**

|:---:|:---|
| **형식화** | - 개인의 암묵지가 조직의 형식지로 발전되었다.<br>- 분석가의 경험을 바탕으로 정리하여 문서화한다. |
| **체계화** | - 문서화한 최적화된 형식지로 전개됨으로써 방법론이 생성되었다.<br>- 문서에는 절차나 활동 및 작업, 산출물, 도구 등을 정의한다. |
| **내재화** | - 개인에게 전파되고 활용되어 암묵지로 발전되었다.<br>- 전파된 방법론을 학습하고 활용하여 내재화한다. |

<br>

#### **5-2) 계층적 프로세스 모델 구성**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
분석 방법론은 일반적으로 **계층적 프로세스 모델 형태로 구성 가능하며, 단계, 태스크, 스텝 3계층으로 구성된다.**
</blockquote>

1. 최상위 계층 - 단계(Phase)
    - 프로세스 그룹을 통하여 완성된 단계별 산출물을 생성
    - 각 단계는 **기준선으로 설정되어 관리되어야 하며 버전관리 등을 통하여 통제 한다.**

2. 중간 계층 - 태스크(Task) 
    - 각 **태스크는** 단계를 구성하는 단위 활동이다.
    - **물리적 또는 논리적 단위로 품질검토가 가능**하다.

3. 최하위 계층 - 스텝(Step)
    - **WBS**의 워크패키지이다.
    - 입력자료, 처리 및 도구, 출력자료로 구성된 단위 프로세스이다.

<br>

#### **5-3) KDD 분석 방법론**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**KDD**는 1996년 **Fayyad**가 **통계적인 패턴이나 지식을 탐색하는** 데 활용할 수 있도록 체계적으로 정리한 프로파일링 기술 기반의 **데이터 마이닝 프로세스다.**
</blockquote>

1. **KDD** 분석 방법론의 **9가지 프로세스**

    | 단계 | 내용 |
    |:---:|:---| 
    | 1. | 분석 대상 **비즈니스 도메인의 이해** |
    | 2. | 분석 대상 **데이터셋** 선택과 생성 |
    | 3. | 데이터에 포함되어 있는 **잡음(Noise)과 이상값(Outlier) 등을 제거하는 정제작업이나 전처리** |
    | 4. | 분석 목적에 맞는 변수를 찾고 필요시 데이터의 **차원을 축소하는 데이터 변경** |
    | 5. | 분석 목적에 맞는 **데이터 마이닝 기법 선택** |
    | 6. | 분석 목적에 맞는 **데이터 마이닝 알고리즘 선택** |
    | 7. | **데이터 마이닝** 시행 |
    | 8. | **데이터 마이닝 결과에 대한 해석** |
    | 9. | **데이터 마이닝에서 발견된 지식 활용** |
 
<br>

2\. **KDD** 분석 방법론의 분석 절차

- 데이터 분석은 **총 5단계**에 걸쳐 진행된다.

    | 단계 |  | 내용 |
    |:---:|:---| 
    | 1. | **데이터셋 선택**<br>(Selection) | - 분석대상 비즈니스 도메인에 대한 이해 및 프로젝트 목표의 정확한 설정<br>- 필요시에 목표 데이터를 추가적으로 구성하여 활용 |
    | 2. | **데이터 전처리**<br>(Preprocessing) | - **잡음(Noise)과 이상값(Outlier), 결측치(Missing Value)**를 식별하고 필요시 제거하거나 대체<br>- 데이터가 추가적으로 필요한 경우 데이터셋 선택 절차부터 다시 실행 |
    | 3. | **데이터 변환**<br>(Transformation) | - 분석 목적에 맞는 변수를 선택하거나 **차원 축소** 등을 수행<br>- **학습용 데이터**와 **검증용 데이터**로 데이터를 **분리** |
    | 4. | **데이터 마이닝**<br>(Data Mining) | - 분석 목적에 맞는 데이터 마이닝 기법 및 알고리즘을 선택하여 분석을 수행<br>- 필요시 데이터 전처리와 변환 절차를 추가로 실행 |
    | 5. |**데이터 마이닝 결과 평가**<br>(Interpretation / Evaluation) | - 분석 결과에 대한 해석과 평가 및 분석 목적과의 일치성 확인<br>- 발견된 지식을 업무에 활용하기 위한 방안을 모색한다. |
 
<br>

#### **5-4) CRISP-DM 분석 방법론**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**CRISP-DM**은 계층적 프로세스 모델로써 **4계층으로 구성된** **데이터 마이닝** 프로세스이다.
</blockquote>

1. **CRISP-DM** 분석 방법론의 **4계층**
    - 최상위 레벨: 여러 개의 단계로 구성
    - 일반화 태스크: 데이터 마이닝의 **단일 프로세스**를 완전하게 수행하는 단위
    - 세분화 태스크: **일반화 태스크**를 구체적으로 수행
    - 프로세스 실행: **데이터 마이닝**을 구체적으로 실행

2. **CRISP-DM 분석 방법론의 분석 절차**
    1. 업무 이해
    2. 데이터 이해
    3. 데이터 준비
    4. 모델링
    5. 평가
    6. 전개

<br>

#### **5-5) SEMMA 분석 방법론**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**SEMMA**는 **SAS Institute**의 주도로 만들어진 기술과 **통계 중심의** 데이터 마이닝 프로세스이다.
</blockquote>

**SEMMA** 분석 방법론의 특징<br>
- **SAS Institute**의 데이터 마이닝 도구와 손쉽게 접목하여 활용할 수 있다.<br>
- 주로 데이터 마이닝 프로젝트의 모델링 작업의 중점을 두고 있다.<br>

<br>

**SEMMA 분석 방법론의 분석절차**<br>

1. **추출(Sample)**
2. **탐색(Explore)**
3. **수정(Modify)**
4. **모델링(Model)**
5. **평가(Assess)**

<img src="/assets/img/semma.png" width="100%">

<br>
<br>

### 6. 데이터 분석 거버넌스

#### **6-1) 데이터 분석 거버넌스 개요(Governance)**

**데이터 분석 거버넌스의 필요성**

- 데이터 분석 업무를 하나의 기업 문화로 정착하고 이를 지속적으로 고도화 해나가기위해 필요하다.

<br>

**데이터 분석 거버넌스의 구성요소**

- 데이터 분석 기획과 관리를 수행하는 조직(Organization)
- 데이터 분석 과제 기획과 운영 프로세스(process)
- 데이터 분석 지원 인프라(System)
- 데이터 거버넌스(Data)
- 데이터 분석 교육 및 마인드 육성 체계(Human Resource)

<br>

#### **6-2) 데이터 거버넌스**

1. 데이터 거버넌스의 필요성

    - 개별 시스템 단위로 데이터를 관리할 경우 데이터 중복, 비표준화에 따른 정합성 오류 등으로 데이터 활용도가 저하될 수 있다.
    - 빅데이터 프로젝트의 효과적 추진 및 효과의 지속성을 얻기 위해서는 데이터 거버넌스 체계 수립이 필요
    - 데이터 거버넌스가 없는 빅데이터의 적용은 단발성 효과에 불과할 가능성이 높다.

2. **데이터 거버넌스 정의**

    - 전사 차원의 모든 데이터에 대하여 **정책 및 지침, 표준화, 운영조직과 책임 등의 표준화된 관리 체계를 수립하고 운영하기 위한 프레임워크와 저장소를 구축하는 것이다.**

3. 데이터 거버넌스의 주요 관리 대상

- **마스터 데이터(Master Data)**
    - 마스터 파일을 형성하는 데이터이며, 데이터를 처리 및 조작하기 위하여 사용되는 기본 데이터이다.

- **메타 데이터(Meta Data)**
    - 데이터에 대한 구조화된 데이터이며, **다른 데이터를 설명하기 위해 사용되는 데이터이다.**

- **데이터 사전(Data Dictionary)**
    - 효과적인 데이터 자원관리를 위해 **자료의 이름, 표현 방식, 자료의 의미와 사용 방식, 다른 자료와의 관계 등**을 저장해놓은 데이터이다.

<br>

**데이터 거버넌스의 특징**

- 데이터의 **가용성, 유용성, 통합성, 보안성, 안전성**을 확보할 수 있다.
- 빅데이터 프로젝트를 성공으로 이끄는 기반을 마련할 수 있다.

<br>

**빅데이터 거버넌스의 구성요소**

- 원칙
    - 데이터를 유지하고 관리하기 위한 지침 및가이드
    - 보안, 품질기준, 변경관리 등

- 조직
    - 데이터를 관리할 조직의 역할과 책임
    - 데이터 관리자, 데이터베이스 관리자, 데이터 아키텍트 등

- 프로세스
    - 데이터 관리를 위한 활동과 체계
    - 작업 절차, 모니터링 활동, 측정 활동 등

<br>

**데이터 거버넌스의 체계**

<img src="/assets/img/governance.jpeg" width="100%">

<br>
<br>

### 7. 데이터 분석 수준진단

#### **7-1) 데이터 분석 수준진단 개요**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
데이터 분석의 **수준진단**을 통해 데이터 분석 기반을 만들기 위해 무엇을 준비하고 더 보완해야 하는지 확인 가능하고, 데이터 분석의 **유형이나 방향을 결정할 수 있다.**
</blockquote>

**분석 수준진단 목표**

- 조직이 현재 수행하고 있는 데이터 분석 수준을 명확히 이해하고, 수준진단 결과를 바탕으로 **미래 목표수준을 정의**
- 타사 대비 어느 정도 수준이고, 어느 영역에 선택과 집중을 해야 하는지, 무엇을 보완해야 하는지 등 개선 방안 도출

<br>

**분석 수준진단 프레임워크**

- **6개** 영역의 분석 준비도와 3개 영역의 분석 성숙도를 동시에 평가할 수 있다.

<img src="/assets/img/data-수준진단.png" width="100%">

<br>

#### **7-2) 분석 준비도(Readiness)**

1. 분석 준비도 정의
    - 조직 내 데이터 분석 업무 도입을 목적으로 현재 수준을 파악하기 위한 진단방법이다.

2. 분석 준비도의 원리
    - **총 6가지 영역**을 대상으로 현재 수준을 파악한다.
    - 각 진단 영역별로 세부 항목에 대한 수준까지 파악
    - 만일 일정 수준 이상 충족되지 못하면 데이터 분석 환경을 먼저 조성한다.

<br>

#### **7-3) 분석 성숙도 모델**

1. 분석 성숙도 모델의 정의
    - 데이터 분석 능력 및 데이터 분석 결과 활용에 대한 조직의 성숙도 수준을 평가하여 현재 상태를 점검하는 방법

2. 분석 성숙도 모델의 특징
    - **비즈니스 부문, 조직 및 역량 부문, IT 부문 총 3단계 부문으로 대상으로 실시한다.**
    - 성숙도 수준에 따라 **도입, 활용, 확산, 최적화 단계로 구분한다.**

<br>

#### **7-4) 분석 수준진단 결과**

1. 분석 준비도 및 성숙도 진단 결과
    - 조직의 현재 데이터 분석 수준을 객관적으로 파악할 수 있다.
    - 타사의 데이터 분석 수준과 비교하여 데이터 분석 경쟁력 확보 및 강화를 위한 목표 수준 설정이 가능하다.

2. 사분면 분석(Analytics Quadrant)

    - 데이터 분석 관점에서 **4가지 유형으로** 데이터 분석 수준진단 결과를 구분한다.
    - 향후 고려해야 하는 데이터 분석 수준에 대한 목표나 방향을 정의할 수 있으며, 유형별 특성에 따라 개선방안을 수립할 수 있다.

<img src="/assets/img/4분면.png" width="100%">

<br>
<br>
<br>

## 02. 분석 작업 계획

---

### 1. 분석 작업 개요

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
분석 작업 계획을 수립하기 위해 **데이터 처리 프로세스 전체에 대한 이해가 필요하며, 데이터 처리 영역과 데이터 분석 영역으로 나누어 살펴볼 수 있다.**
</blockquote>

**데이터 처리 영역**

데이터 분석을 위한 기초 데이터를 정의하고 수집 및 저장, 분석하기 수월하도록 물리적인 환경을 제공하는 영역이다.

| 단계 | 내용 |
|:---:|:---|
| 데이터 소스 | - 기업 내 각 부서나 서비스별 적재되고 있는 내부 데이터와<br>-  다른 기업이나 공공 데이터 등 외부 데이터가 있다. |
| 데이터 수집 | - 사용자로부터 데이터를 직접 입력받거나<br>- 로그수집기, 크롤링, 센서네트워크 등을 통해 데이터를 수집 |
| 데이터 저장 | - 데이터를 유형별로 나눠 최적의 설계를 하여 데이터 스토리지에 저장 |
| 데이터 처리 | - 저장된 대용량의 데이터를 신속하고 정확하게 처리하기 위해<br>- 실시간 처리 및 분산 처리 등을 시도 |

<br>

**데이터 분석 단계 - NCS(국가직무능력표준)**

| 구분 | 내용 |
| 도메인 이슈 도출 | - 분석 대상 과제 현황을 파악하고 개선과제를 정의<br>- 문제의 주요 이슈별로 개선방향을 도출하고, 개선방안을 수립하며, 빅데이터 요건 정의서를 작성 |
| 분석 목표 수립 | - 빅데이터 요건 정의서를 토대로 개선방향에 맞는 현실적인 분석목표를 수립<br>- 데이터 관련 정보, 분석 타당성 검토, 성과측정 방법 등을 포함한 분석목표 정의서를 작성 |
| 프로젝트 계획 수립 | - 사전에 책정된 자원과 예산, 기간 등을 고려하여 분석 프로젝트 계획을 수립<br>- 분석목표정의서, 프로젝트 소요비용 배분계획을 바탕으로 작업분할구조도를 작성 |
| 보유 데이터 자산 확인 | - 분석목표와 프로젝트 계획을 기반으로 현재 보유 중인 데이터의 품질이나<br>- 규모, 유형 등을 확인하고 법률적 이슈나 제약사항 등을 검토 |

<br>
<br>

### 2. 데이터 확보 계획

#### **2-1) 데이터 확보를 위한 사전 검토사항**

1. 필요 데이터 정의
    - 분석 목적에 맞는 데이터를 정의하고, 필요한 데이터를 확보할 수 있는지 확인
    - 확인할 수 없다면 대안을 함께 고려

2. 편향되지 않고 충분한 양의 데이터 규모
    - 데이터 분석 기법에 따라 **훈련 데이터셋, 검증 데이터셋, 테스트 데이터셋이 필요**
    - 신뢰성 높은 데이터 분석 모형 개발과 정확한 데이터 분석을 위해 **3가지 데이터셋으로 나누어** 사용할만큼 충분한 데이터가 확보되야한다.

3. 내부 데이터의 사용
    - 필요 데이터에 대한 데이터 목록을 작성
    - 목록은 변수 명칭, 설명, 형태, 기간, 용량, 권한 등을 작성
    - **개인정보일 경우 비식별 조치방안을 함께 고려**

4. 외부 데이터 수집
    - 필요 데이터에 대한 데이터 목록을 데이터를 보유한 기업의 이름과 데이터 **제공 방법(Open API, 복제 등)까지 고려**
    - 필요 데이터에 대하여 보유 기업으로부터 데이터 제공 가능여부와 구매 비용 등을 협의

5. 데이터 수집 방법
    - 설문조사
    - 관찰
    - 실험
    - 웹 크롤링
    - 소셜 미디어 분석
    - 데이터베이스 및 기존 데이터 활용
    - **FGI**: 일반적으로 마케팅, 소비자 인사이트, 제품개발, 서비스 향상 등의 목적으로 사용되는 질적 연구 방법
    - 스크래퍼

<br>

#### **2-2) 생성된 분석 변수의 정제를 위한 점검항목 정의**

분석 기획 단계에서 도출된 문제 인식, 해결을 위한 개념적 대안 설계를 통해 도출된 데이터에 대해 가용성을 평가하고 점검항목을 정의한다.

| 분류 | 점검 항목 | 내용 |
|:----:|:------------|:---|
| **데이터 수집** | 데이터 적정성 | - 문제 해결에 적절한 분석 변수인가? |
| 데이터 수집 | 데이터 가용성 | - 수집 가능한 데이터인가? |
| 데이터 수집 | 대체 분석 데이터 유무 | - 수집 불가능한 데이터인 경우 간접적으로 연관성 있는 데이터로 대체 가능한가? |
| **데이터 적합성**| 데이터 중복 | - 중복이나 노이즈 제거, 데이터값 존재 유무 등 기초 데이터 클렌징 수행 가능한가? |
| 데이터 적합성 | 분석 변수별 연관성 | - 분석 변수별 측정될 수 있는 min/max를 확인했는가? |
| 데이터 적합성 | 분석 변수별 연관성 | - 수집된 데이터 간 충분 가격으로 연관성이 있는가? |
| 데이터 적합성 | 데이터 내구성 | - 데이터 노이즈, 왜곡이 발생하였을 때 예측 성능을 보장할 수 있는가? |
| **특징 변수** | 특징 변수 사용 | - 분석 변수 중 바로 특징 변수로 사용할 수 있는 가능성이 있는가? |
| 특징 변수 | 변수 간 결합 가능 여부 | - 분석 변수를 결합하여 교차 검증을 할 수 있는가? |
| **타당성** | 편익/비용 검증 | - 분석 비용과 분석 후 결과가 추가적 매출, 수익 등에 기여할 수 있는가? |
| 타당성 | 기술적 타당성 | - 다양한 분석 툴을 활용할 수 있는 분석 변수를 도출하였는가? |

<br>
<br>

### 3. 생성 변수의 검증 방안 수립

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
모든 개별 데이터에 대한 타당성 보장보다는 빅데이터 개념 및 특성 측면에서 관리되어야 하는 항목과 수준에 대해 품질 검증을 정의
</blockquote>

**빅데이터 주요 품질 지표**

- **정확성**
- **완전성**
- **적시성**
- **일관성**

<br>

**일반적 데이터 분석 절차**

1. 문제 인식
2. 연구조사
3. 모형화
4. 데이터 수집
5. 데이터 분석
6. 분석 결과 제시
