---
layout: post
title: "[선형대수] 03 - 벡터의 노름과 거리"
description: "[선형대수] 고차원 공간에서의 거리 개념"
author: "DoorNote"
date: 2025-12-19 10:00:00 +0900
#  permalink: //
categories:
    - AI | 인공지능
    - 선형대수
tags: [벡터, 노름, 거리, 코사인유사도]
use_math: true
comments: true
pin: false # 고정핀
math: true
mermaid: true
image: /assets/img/Vector_Norm.png

---

## 들어가며

> 이번 포스팅은 **고차원 공간에서의 거리 개념**을 다룬다.  
> **벡터의 노름과 다양한 거리 측정 방법**들을 이해하고, **AI/ML에서 어떻게 활용**되는지 알아보려 한다.
{: .prompt-tip }

<br>
<br>

## Norm

---

### 1. Vector Norm 이란?

> **벡터 Norm**은 벡터의 **크기(길이)를 측정하는 함수**로, 고차원 공간에서 벡터의 **절대적인 크기**를 나타낸다.
{: .prompt-info }

- Norm은 **절대값/길이**를 의미하므로 **항상 0 이상 (양수)**
- Norm은 **Vector** -> **Scalar**로 바꾼다.
- **Norm**은 길이의 일반화된 개념
- Norm **종류**
  - **L1** Norm (맨해튼 노름)
  - **L2** Norm (유클리드 노름)
  - **L∞** Norm (최대 노름)

![norm](/assets/img/norm.png){: width="600" .center}
_Vector Norm_

**왜 Norm이 중요한가?**

- **벡터 비교**: 서로 다른 벡터의 크기를 정량적으로 비교
- **정규화**: 벡터를 **단위 길이로 만들어 방향만 보존**
- **거리 계산**: 벡터 간 거리 측정의 기초
- **최적화**: 손실 함수에서 **정규화 항**으로 활용

<br>
<br>

### 2. L1 Norm (맨해튼 노름)

> **L1 Norm** (맨해튼 노름)은 **벡터 성분 절댓값의 합으로 정의**되며, **벡터의 길이를 계산**하는 방법 중 하나다.
{: .prompt-info }

![L1 Norm](/assets/img/L1.png){: width="650" .center}
_L1 Norm_

**기하학적 의미**

- 벡터의 크기를 **각 성분의 절댓값 합**으로 측정
- 원점에서 해당 점까지 **격자 형태로 이동**하는 경로의 총 거리
- **다이아몬드 형태**의 등거리선(norm ball) 형성

**주요 특징**

- **희소성(Sparsity) 유도**: 많은 가중치를 **정확히 0으로 만듦**
- **Lasso 회귀**: 자동 변수 선택 효과
- **아웃라이어에 강건**: 극값의 영향 적음

<br>
<br>

### 3. L2 Norm (유클리드 노름)

> **L2 Norm** (유클리드 노름)은 **벡터 성분의 제곱합의 제곱근으로 정의**되며, **일반적인 거리 개념**을 나타낸다.
{: .prompt-info }

![L2 Norm](/assets/img/L2.png){: width="650" .center}
_L2 Norm_

**기하학적 의미**

- 벡터의 크기를 **성분의 제곱합의 제곱근**으로 측정
- 원점에서 해당 점까지의 **직선 거리** (최단 거리)
- **원 형태**의 등거리선(norm ball) 형성

**주요 특징**

- **미분** 가능: **비선형 최적화**에 적합
- **Ridge 회귀**: 가중치 수축으로 과적합 방지
- **아웃라이어에 민감**: 극값의 영향 큼

<br>
<br>
<br>

## Distance

---

### 1. Vector Distance 란?

> **두 벡터 간의 차이나 유사성을 측정하는 함수**로, 고차원 공간에서 **데이터 포인트 간의 관계**를 정량화한다.
{: .prompt-info }

- 거리는 **두 벡터** -> **스칼라**로 변환
- **항상 0 이상의 값**을 가지며, **같은 벡터 간의 거리는 0**
- **대칭성**: d(a, b) = d(b, a)
- **거리 종류**
  - **유클리드 거리** (Euclidean Distance)
  - **맨해튼 거리** (Manhattan Distance)  
  - **코사인 거리/유사도** (Cosine Distance/Similarity)

![Vector_Distance](/assets/img/Vector_Distance.png){: width="800" .center}
_Vector Distance_

**왜 Distance가 중요한가?**

- **데이터 분류**: KNN, 클러스터링에서 유사한 데이터 그룹핑
- **추천 시스템**: 사용자/아이템 간 **유사도** 계산
- **이상 탐지**: 정상 데이터와의 **거리로** 이상값 검출
- **차원 축소**: 거리 보존을 통한 **데이터 압축**

<br>
<br>

### 2. 맨해튼 거리 (Manhattan Distance)

> **맨해튼 거리**는 **L1 Norm을 기반으로 격자 형태로 이동하는 거리를 측정**하며, **택시 거리**라고도 불린다.
{: .prompt-info }

![맨해튼-거리](/assets/img/맨해튼-거리.png){: width="400" .center}
_맨해튼 거리_

**기하학적 의미**

- 두 점 간의 **격자 경로 거리** (수직+수평 이동)
- 맨해튼 도로망에서 **택시가 이동하는 거리**와 동일
- **대각선 이동 불가능**한 환경의 거리

**주요 특징**

- **계산 효율**: 제곱근 연산 불필요
- **희소성**: 차이가 작은 차원 무시
- **로버스트**: 아웃라이어에 덜 민감 (절댓값만 사용하기에)

<br>
<br>

### 3. 유클리드 거리 (Euclidean Distance)

> **유클리드 거리**는 **L2 Norm을 기반으로 두 벡터 간의 직선 거리를 측정**하며, **가장 직관적인 거리 개념**이다.
{: .prompt-info }

![유클리드-거리](/assets/img/유클리드-거리.png){: width="400" .center}
_유클리드 거리_

**기하학적 의미**

- 두 점 간의 **최단 직선 거리** (피타고라스 정리)
- 2차원에서는 **삼각형의 빗변** 길이와 동일
- 고차원에서도 **직선 거리**의 일반화

**주요 특징**

- **직관적**: 일반적인 물리적 거리와 일치 (직선 거리를 사용하기에)
- **회전 불변**: 좌표계 회전에도 거리 보존 (유클리드 성질을 따르기에)
- **제곱 거리**: 연산 효율을 위해 제곱근 생략 가능 (대소 비교만 필요하기에)

<br>
<br>

### 4. 코사인 유사도 (Cosine Similarity)

> **코사인 유사도**는 **벡터 간 각도를 측정**하여 **방향의 유사성**을 나타내며, **벡터 크기에 무관**한 유사도를 제공
{: .prompt-info }

![코사인 거리](/assets/img/코사인-거리.jpg){: width="400" .center}
_코사인 거리_

**기하학적 의미**

- 두 벡터가 이루는 **각도의 코사인 값**
- **-1(반대)부터 1(동일) 사이**의 값
- 벡터의 **방향만** 고려, **크기 무시**

**주요 특징**

- **크기 무관**: 벡터 길이에 영향받지 않음 (정규화 후 내적을 계산하기에)
- **문서 유사도**: NLP에서 텍스트 유사도 측정 (방향만 비교하기에)
- **추천 시스템**: 사용자 선호도 패턴 분석 (상대적 선호도를 비교하기에) 