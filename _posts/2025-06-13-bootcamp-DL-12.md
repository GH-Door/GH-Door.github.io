---
layout: post
title: "[Upstage AI Lab] 12주차 - DL-Basic"
description: "[Upstage AI Lab] Deep Learning 기본 개념 정리"
author: "DoorNote"
date: 2025-06-13 10:00:00 +0900
#  permalink: //
categories:
    - AI | 인공지능
    - Upstage AI Lab
tags: [Deep Learning]
use_math: true
comments: true
pin: false # 고정핀
math: true
mermaid: true
image: /assets/img/DL-basic.png
---

## 들어가며

> 이번 주차부터 **Deep Learning**에 대한 강의가 시작됐다.  
> 딥러닝의 발전 단계와 기본 개념 등  **Deep Learning**의 전반적인 흐름을 정리했다.
{: .prompt-tip }

<br>
<br>

## Deep Learning 발전 단계

---

### 딥러닝의 발전 5단계

> **딥러닝**의 전체적인 발전 과정을 **총 5단계**로 나누게 되는 과정에 대한 내용이다.  
> **아래의 그림**처럼 다섯 단계로 분류가 되며 단계별로 **딥러닝이 진화**되어 왔다.
{: .prompt-info }

![딥러닝의 발전](/assets/img/DL-발전.png){: width="800" .center}

**주요 5단계**

- Rule Based Programming
- Conventional Machine Learning
- Deep Learning
- Pre-training & Fine-tuning
- Big Model & Zero/Few shot

<br>
<br>

### Step 1: Rule Based Programming

> **규칙 기반 프로그래밍**이라고 하며 사람이 고안한 **IF–THEN** 형태의 규칙으로 분류, 판단 로직을 만든다.  
> **SW1.0** 방식이라고도 부른다.
{: .prompt-info }

![Step-1](/assets/img/DL-Step1.png){: width="500" .center}

**예시**

- 이미지에서 **모양, 색상, 질감** 등 사람이 정의한 특징을 살펴봄  
- 특정 규칙(예: 귀가 뾰족하고, 수염 패턴이 있으면) 충족 시 “고양이”로 분류  
- 모든 **판단 로직과 연산**을 **사람이 직접 설계**

<br>
<br>

### Step 2: Conventional Machine Learning

> 이번 단계에서도 **feature 추출**은 사람이 수행한다.  
> 하지만 **모델 학습·파라미터 최적화**를 기계가 자동으로 수행하는 방식을 **SW2.0**이라 한다.  
> (일부에서는 SW1.0과 SW2.0의 특징을 섞은 중간 단계로 **SW1.5**라 부르기도 한다)
{: .prompt-info }

![Step-2](/assets/img/DL-Step2.png){: width="600" .center}

**예시**

- 이미지에서 **윤곽선, 색상 분포, 질감** 등 사람이 정의한 특징을 추출  
- 추출된 특징을 **벡터**로 변환해 학습 데이터로 입력  
- **SVM**이나 **Random Forest**가 패턴을 학습해 분류 경계 생성  
- 학습된 모델을 사용해 **새로운 데이터**를 예측

<br>
<br>

### Step 3: Deep Learning

> **SW2.0**에서 사람이 수행하던 **feature 정의** 단계를 제거하고, **자동으로 특징을 추출·학습**하는 단계다.  
> 이를 **SW3.0(딥러닝)**이라고도 하며, **end-to-end**로 입력부터 예측·생성까지 처리할 수 있다.
{: .prompt-info }

![Step-3](/assets/img/DL-Step3.png){: width="600" .center}

**예시**

- 원시 이미지(픽셀 값)를 그대로 **Neural Network**에 입력  
- **다층 합성곱 레이어**가 계층적으로 **feature**를 자동 추출  
- **Dense 레이어**가 추출된 특징으로 **분류 경계**를 학습  
- 학습된 모델이 **새로운 이미지**를 **자동으로 예측**

<br>
<br>

### Step 4: Pre-training & Fine-tuning

> 3단계 딥러닝의 한계는 **Task**가 바뀔 때마다 매번 새로운 모델을 처음부터 학습해야 한다는 점이었다.  
> 이를 해결하기 위해 **대규모 데이터**로 미리 학습한 **Pre-training 모델**을 활용한다.  
> 필요할 때마다 해당 모델을 불러와 **Fine-tuning**을 거쳐 원하는 분류·회귀 작업을 수행한다.
{: .prompt-info }

![Step-4](/assets/img/DL-Step4.png){: width="700" .center}

**Pre-training**

- ImageNet 등 **대표적인 대규모 데이터셋**으로 네트워크 전체를 **사전 학습**  
- 모서리·텍스처·패턴 등 **저수준 feature**를 자동 추출하도록 가중치 학습  
- 다양한 downstream Task에서 **기초 표현(feature extractor)**으로 재사용 가능  

<br>

**Fine-tuning**

- Pre-trained 모델의 **상위 레이어**(분류기 헤드 등)를 대상 Task 데이터로 **재학습**  
- 전체 또는 일부 레이어를 **낮은 학습률**로 미세 조정해 빠르게 적응  
- 최소한의 학습 비용으로 Task-specific 성능을 **극대화**

<br>
<br>

### Step 5: Big Model & Zero/Few shot

> **추가 학습 없이** 단일 거대 모델만으로 모든 작업을 처리하는 단계. **(SW3.0)**   
> **0-shot** 또는 **few-shot** 예시만으로 **Task**를 지시하면 즉시 결과를 생성한다.  
> 주로 텍스트 모델에 적용되며, 대표 사례로 **GPT-3**가 있다.  
{: .prompt-info }

![Step-5](/assets/img/DL-Step5.png){: width="800" .center}

- 태스크별 **별도 모델 학습** 불필요  
- Task-specific 데이터 **수집·라벨링** 없이 **즉시 활용**  
- 거대한 단일 모델 하나로 **다양한 문제 해결**  
- **Pre-training & Fine-tuning** 대비 **추가 비용·시간** 대폭 절감

<br>

**Shot 개념**

- **Zero-shot**: 태스크 설명만 제공  
- **One-shot**: 예시 1개 제공  
- **Few-shot**: 소수의 예시(여러 개) 제공

<br>

**In-context learning vs Pre-training & Fine-tuning**

| 항목                | Pre-training & Fine-tuning | In-context Learning |
|--------------------|-----------------------------|---------------------|
| 추가 학습 여부      | 필요                        | 불필요              |
| 데이터 준비        | Task별 대규모 데이터 필요   | 태스크 설명·소량 예시만  |
| 모델 수            | Task별 각각 모델            | 하나의 통합 모델    |
| 적용 비용·시간     | 높음                        | 낮음                |

<br>
<br>
<br>

## 

---

### 1. 