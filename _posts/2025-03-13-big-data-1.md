---
layout: post
title: "[빅분기] 필기 Chapter 01. 빅데이터의 이해"
description: "[빅데이터분석기사] 필기 'Chapter 01. 빅데이터의 이해' 내용을 정리했습니다."
author: "DoorNote"
date: 2025-03-13 10:00:00 +0900
permalink: /big-data-1/
categories:
    - 자격증
    - 빅데이터분석기사
tags: [빅데이터분석기사, PART01 빅데이터 분석 기획]
comments: true
pin: false # 고정핀
math: true
mermaid: true
image: /assets/img/빅데이터분석기사.png
---

## 들어가며

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**빅데이터분석기사 필기 시험**을 준비하며 공부한 내용을 **Chapter** 별 핵심 내용 기준으로 정리한 내용입니다.<br>
교재는 [이기적-빅데이터분석기사 필기-2024](https://search.shopping.naver.com/book/catalog/41869053620?cat_id=50010601&frm=PBOKPRO&query=%EC%9D%B4%EA%B8%B0%EC%A0%81+%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC+%ED%95%84%EA%B8%B0&NaPm=ct%3Dm88q4ot4%7Cci%3D23875283d14200743013ebc63ca27206ecd57363%7Ctr%3Dboknx%7Csn%3D95694%7Chk%3Dd90241b163c19c2f3cce4b072ef86e71d42f9d26)로 공부했습니다.   
</blockquote>

<br>
<br>

## 01. 빅데이터 개요 및 활용

---

### 1. 데이터와 정보

#### **1-1) 데이터 정의**

- 데이터는 **추론**과 추정의 **근거**를 이루는 **사실**이다.<br>
- **현실 세계에서** 관찰하거나 측정하여 수집한 사실이다.

#### **1-2) 데이터 특징**

- 단순한 객체로도 가치가 있으며 다른 객체와의 **상호관계** 속에서 더 큰 가치를 갖는다.<br>
- 객관적 사실이라는 존재적 특성을 갖는다.<br>
- **추론, 추정, 예측, 전망**을 위한 근거로써 당위적 특성을 갖는다. 

#### **1-3) 데이터 구분**

1. 정량적 데이터: 주로 숫자로 이루어진 데이터<br> 
*(ex: 2025년, 100km/h 등)*

2. 정성적 데이터: 문자와 같은 Text로 구성되며 함축적 의미를 갖고 있다.<br>
*(ex: 귀찮다. 등)*

**✅ TIp: 정량적 데이터는 주로 객관적 내용을, 정성적 데이터는 주로 주관적 내용을 내포하고 있다.**

<br>

| 비고 | 정량적 데이터 | 정성적 데이터 |
|:----:|:------------:|:------------:|
| 유형 | 정형 데이터, 반정형 데이터 | 비정형 데이터 |
| 특징 | 여러 요소의 결합으로 의미 부여 | 객체 하나가 함축된 의미 내포 |
| 구성 | 수치나 기호 등 | 문자나 언어 등 |
| 형태 | DB, 스프레드시트 등 | 웹 로그, Text 파일 등 |
| 분석 | 통계 분석 용이 | 통계 분석 어려움 |

<br>

#### **1-4) 데이터 유형**

1. 정형 데이터: **정해진 형식과 구조에** 맞게 저장되도록 구성된 데이터이며, **연산이 가능**<br>
*(관계형 DB의 Table에 저장되는 데이터 등)*

2. 반정형 데이터: 데이터 형식과 **구조가 비교적 유연하고**, **스키마 정보를 데이터와 함께 제공**하는 파일 형식의 데이터이다.<br>
 **연산이 불가능** *(JSON, XML, HTML 등)*

3. 비정형 데이터: 구조가 **정해지지 않은** 대부분의 데이터이며, **연산이 불가능**<br>
*(동영상, 이미지, 음성, 문서, 메일 등)*

<br>

| 비고 | 특징 | 연산 여부 | 종류 |
|:----:|:------------:|:------------:|
| 정형 데이터 | 정형화된 스키마를 가진 데이터 | 가능 | 관계형 DB, Table 등 |
| 반정형 데이터 | 메타 구조를 갖는 데이터 | 불가능 | JSON, XML, HTML 등 |
| 비정형 데이터 | 일정한 구조가 없는 데이터 | 불가능 | 동영상, 이미지, 음성, 메일 등 | 


<br>

#### **1-5) 데이터의 근원에 따른 분류**

- 가역 데이터: 생산된 데이터의 원본으로 **일정 수준 환원이 가능한 데이터**<br>
- 불가역 데이터: 생산된 데이터의 원본으로 **환원이 불가능한 데이터**<br>
*(현실에선 가역 데이터 보다 불가역 데이터가 많다.)*

<br>

| 비고 | 가역 데이터 | 불가역 데이터 |
|:----:|:------------:|:------------:|
| 환원성(추적성) | 가능(비가공 데이터) | 불가능(가공 데이터) |
| 의존성 | 원본 데이터 자체 | 원본 데이터와 독립된 새 객체 |
| 원본과의 관계 | 1:1 관계 | 1:N, N:1, M:N 관계|
| 처리과정 | 탐색 | 결합 |
| 활용분야 | 데이터 마트, 데이터 웨어하우스 | 데이터 전처리, 프로파일 구성 |

<br>

#### **1-6) 지식창조 매커니즘**

- 지식창조 매커니즘은 다음 **4단계**로 구성된다.

1. 공통화: 서로의 경험이나 인식을 공유하며 **한 차원 높은 암묵지**로 발전시킨다.<br>
2. 표출화: 암묵지가 구체화되어 **외부(형식지)**로 표현된다.<br>
3. 연결화: 형식지를 **재분류**하여 체계화한다.<br>
4. 내면화: 전달받은 형식지를 다시 개인의 것으로 만든다.

<br>

#### **1-7) 가치창출 프로세스**

- 데이터, 정보, 지식, 지헤는 인간의 사회활동 속에서 가치창출을 위한 일련의 프로세스로 연결되어 기능한다.

<img src="/assets/img/가치창출-프로세스.png" width="80%">

<br>
<br>

### 2. 데이터베이스

#### **2-1) 데이터베이스 정의**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
데이터베이스 라는 용어는 1963년 미국 SDC가 개최한 심포지엄에서 공식적으로 사용됐다.<br>
**문자, 기호, 음성, 화상, 영상** 등 상호 관련된 다수의 정보 처리 및 정보통신 기기의 의하여 체계적으로 수집, 축적하여, 다양한 용도와 방법으로 이용할 수 있도록 정리한 정보의 집합체이다.
</blockquote>

<img src="/assets/img/DB-DBMS.png" width="80%">

<br>

#### **2-2) 데이터베이스 관리 시스템(DBMS)**

> **DBMS란?** **데이터베이스**를 관리하며 응용 프로그램들이 **데이터베이스**를 공유하며 사용할 수 있는 환경을 제공하는 **SW**다.<br> 
> 종류는 아래와 같다.

| 종류 | 설명 | 예시 |
|:----:|:------------:|:------------:|
| 관계형 DBMS | 데이터를 열과 행을 이루는 **Table**로 표현하는 모델 | **MySQL**, **Oracle**, PostgreSQL |
| 객체지향 DBMS | 정보를 **객체 형태**로 표현하는 모델 | ObjectDB, Versant, db4o |
| 네트워크 DBMS | **그래프 구조**를 기반으로 하는 모델 | Neo4j, OrientDB, ArangoDB |
| 계층형 DBMS | **트리 구조**를 기반으로 하는 모델 | IBM IMS, Windows Registry |

<br>

#### **2-3) 데이터베이스 활용**

1. OLTP(OnLine Transaction Processing)
    - 호스트 컴퓨터와 온라인으로 접속된 여러 단말 간 처리 형태의 하나로 **데이터베이스의 데이터를 수시로 갱신하는 프로세싱**을 말한다.<br>
    - 현재 시점의 데이터만을 데이터베이스가 관리한다는 개념이다.<br>
    *(이미 발생된 트랜잭션에 대해서는 데이터값이 과거의 데이터로 다른 리스크나 테이프 등에 보관될 수 있다.)*

2. **OLAP**(OnLine Analytical Processing)
    - 정보 위주의 분석 처리를 하는 것으로, **OLTP**에서 처리된 트랜잭션 데이터를 분석해 **제품의 판매 추이, 구매 성향 파악, 재무 회계 분석 등을 프로세싱**하는 것을 의미한다.<br>
    - 다양한 비즈니스 관점에서 쉽고 빠르게 다차원적인 데이터에 접근하여 의사결정에 활용할 수 있는 정보를 얻을 수 있게 하는 기술이다.

**OLTP와 OLAP의 비교**

| 구분 | OLTP | OLAP |
|:----:|:------------:|:----:|
| 데이터 구조 | 복잡 | 단순 |
| 데이터 갱신 | 동적으로 순간적 | 정적으로 주기적 |
| 응답 시간 | 수 초 이내 | 수 초에서 몇 분 사이 |
| 데이터 범위 | 수 십일 전후 | 오랜 기간 저장 |
| 데이터 크기 | 수 GB(기가 바이트) | 수 TB(테라 바이트) |
| 데이터 내용 | 현재 데이터 | 요약된 데이터 |
| 데이터 액세스 빈도 | 높음 | 보통 |
| 질의 결과 예측 | 주기적이며 예측 가능 | 예측하기 어려움 |

<br>

#### **2-4) 데이터 웨어하우스(DW: Data Warehoues)**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**데이터 웨어하우스란?** DB에 축적된 데이터를 공통의 형식으로 변환해서 관리하는 데이터베이스다.<br>
DW는 일정한 시간 동안의 데이터를 축적하고 의사결정을 위한 다양한 분석 작업을 수행한다.<br>
</blockquote>

**데이터 웨어하우스 특징**

| 특징 | 내용 |
|:----:|:------------:|
| 주제지향성 | 고객, 제품 등과 같은 중요한 주제를 중심으로 주제와 관련된 데이터들로 구성됨 |
| 통합성 | 데이터가 DW에 입력될 때는 일관된 형태로 변환되며, 전사적인 관점에서 통합됨 | 
| 시계열성 | DW의 데이터는 일정 기간 동안 시점별로 이어짐 |
| 비휘발성 | DW에 일단 데이터가 적재되면 일괄 처리 작업에 의한 갱신 이외에는 변경이 수행되지 않음 |

<br>

- 아래는 데이터 웨어하우스에 간략한 구성이다. *(참고용)*<br>
*(ETL: 여러 소스에서 데이터를 추출, 변환 후 데이터 웨어하우스에 적재하는 통합 프로세스)*

<img src="/assets/img/Data-Warehoues.jpg" width="100%">

<br>
<br>

### 3. 빅데이터 개요

#### **3-1) 빅데이터의 등장과 변화**

1. 데이터 변화
    - 규모(Volume), 형태(Variety), 속도(Velocity)

2. 기술 변화
    - 새로운 데이터 처리, 저장, 분석 기술 및 아키텍쳐
    - 클라우드 컴퓨팅 활용

3. 인재, 조직 변화
    - **Data Scientist** 같은 새로운 인재 필요
    - 데이터 중심 조직

<br>

#### **3-2) 빅데이터의 등장으로 인한 변화**

- 데이터의 가치 판단 기술이 **질(quality)보다 양(quantity)으로 달라졌다.**<br>
- 데이터를 분석하는 방향이 **이론적 인과관계 중심에서 단순한 상관관계로 변화되는 경향이 있다.**

<br>

#### **3-3) 빅데이터의 특징**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
빅데이터 용어가 사용된 초기에 **3V(규모, 유형, 속도)**로 빅데이터의 특징을 설명했으며,<br>
최근에는 빅데이터 분석을 통해 얻을 수 있는 가치와 데이터에 대한 품질의 중요성이 강조되고 있다.
</blockquote>

**빅데이터의 특징**

| 구분 | | 특징 | 내용 |
|:---:|:---:|:---|:---|
| 5V | 3V | **규모(Volume)** | - 데이터 양이 급격하게 증가(대용량화)<br>- 기존 데이터 관리 시스템의 성능적 한계 도달 |
| | | **유형(Variety)** | - 데이터의 종류와 근원 확대**(다양성)**<br>- 정형/반정형/비정형 데이터 확장 |
| | | **속도(Velocity)** | - 데이터 수집과 처리 속도의 변화(고속화)<br>- 대용량 데이터의 신속하고 즉각적인 분석 요구 |
| | +2V | 정확성(Veracity) | - 데이터의 신뢰성, 정확성, 타당성 보장 필수<br>- 고품질의 데이터에서 고수준 인사이트 도출 가능 |
| | | 가치(Value) | - 대용량의 데이터 안에 숨겨진 가치 발굴이 중요<br>- 다른 데이터들과 연계 시 가치가 빠르게 증대 |

<br>

#### **3-4) 빅데이터의 활용**

**빅데이터의 활용을 위한 3요소**

1. 자원: **빅데이터**
2. 기술: **빅데이터플랫폼, AI**
3. 인력: **알고리즈미스트, 데이터 사이언티스트**

| 구성 요소 | 내용 |
|:----:|:---|
| 자원 | • 정형, 반정형, 비정형 데이터를 실시간으로 수집<br>• 수집된 데이터를 전처리 과정을 통해 품질 향상 |
| 기술 | • 분산 파일 시스템을 통해 대용량 데이터를 분산처리<br>• 데이터마이닝 등을 통해 데이터를 분석 및 시각화<br>• 데이터를 스스로 학습, 처리할 수 있는 AI 기술 활용 | 
| 인력 | • 통계학, 수학, 컴퓨터공학, 경영학 분야 전문지식을 갖춘다.<br>• 도메인 지식을 습득하여 데이터 분석 및 결과 해석 |

<br>
<br>

### 4. 빅데이터 가치

#### **4-1) 빅데이터의 기능과 효과**

1. **고객 세분화와 맞추혐 개인화 서비스**를 제공할 수 있다.
2. 빅데이터는 **알고리즘 기반을 의사결정을 지원**하거나 이를 대신한다.
3. 빅데이터는 투명성을 높여 **R&D 및 관리 효율성**을 제고한다.

<br>

#### **4-2) 빅데이터의 가치 측정의 어려움**

1. 데이터 활용 방식
    - 데이터를 재사용하거나 재결합, 다목적용 데이터 개발 등이 일반화되면서 **특정 데이터를 누가, 언제, 어디서, 활용할지** 알 수 없기에 가치를 측정하기 어렵다. 

2. 가치 창출 방식
    - 데이터는 **어떠한 목적을 갖고서 어떻게 가공하는가**에 다라 기존에 없던 가치를 창출할 수 도 있어 사전에 그 가치를 측정하기 어렵다.

3. 분석 기술 발전
    - 데이터는 **지금의 기술 상황에서는 가치가 없어 보일지라도** **새로운 분석 기법이 등장**할 경우 큰 가치를 찾아낼 수 있으므로 당장 그 가치를 측정하기 어렵다.

4. 데이터 수집 원가
    - 데이터는 달성하려는 목적에 따라 **수집하거나 가공하는 비용이 상황에 따라 달라질 수 있어** 그 가치를 측정하기 어렵다.

<br>
<br>

### 5. 데이터 산업의 이해

#### **5-1) 데이터 산업의 진화**

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
데이터 산업은 **데이터 처리 - 통합 - 분석 - 연결 - 권리** 시대로 진화하고 있다.
</blockquote>

1. 데이터 통합 시대
    - **데이터 모델링과 데이터베이스(DB)관리 시스템**이 등장했다.

2. 데이터 분석 시대
    - **대규모 데이터***를 보관하고 관리할 수 있는 **하둡, 스파크** 등의 빅데이터 기술이 등장했다.

3. 데이터 권리 시대
    - 개인이 자신의 데이터를 자신을 위해 사용
    - **자신이 데이터에 대한 권리를 보유하고 있으며, 스스로 행사할 수 있어야 한다는 마이데이터(My Data)가 등장**

<br>
<br>

### 6. 빅데이터 조직 및 인력

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
기업의 경쟁력 확보를 위해 비즈니스 질문을 도출하고, 이를 충족하기 위한 가치를 발굴하며, **비즈니스를 최적화하기 위하여 빅데이터 조직 및 인력 구성 방안을 수립**
</blockquote>

#### **6-1) 필요성**

- 빅데이터와 관련된 기술적인 문제들은 기술의 발전으로 어느 정도 해소됨
- 데이터 분석 및 활용을 위한 조직체계나 분석 전문가 확보에 어려움이 있음
- 데이터 분석 관점의 컨트롤 타워에 대한 필요성 제기 

<br>

#### **6-2) 조직의 역할**

- 전사 및 부서의 분석 업무를 발굴한다.
- 전문적인 분석 기법과 도구를 활용하여 빅데이터 속에서 인사이트를 찾아낸다.
- 발견한 인사이트를 전파하고 이를 실행한다.

<br>

#### **6-3) 데이터 사이언스 역량**

1. 데이터 사이언스 실현을 위한 인문학적 요소
    - **스토리텔링 능력**
    - **커뮤니케이션 능력**
    - 창의력과 직관력
    - 비판적 시각과 열정

2. 데이터 사이언스 한계
    - 분석 과정에서 **가정과 같이 인간의 해석이 개입되는 단계는 불가피하다.**
    - 분서 결과를 바라보는 사람에 따라 **서로 다른 해석과 결론**을 내릴 수 있다.
    - 아무리 정량적인 분석이라 할지라도 모든 분석은 **가정**에 근거한다.

<br>

#### **6-4) 데이터 사이언티스트**

- 데이터에 대한 이론적 지식과 숙련된 분석 기술을 바탕으로 통찰력과 전달력 및 협업 능력을 갖춘 분야 전문가이다.
- 데이터의 다각적 분석을 통해 인사이트를 도출하고 조직의 전략 방향 제시에 활용할 수 있는 **기획자이기도** 하다.
- **문제를 집중적으로 파고들어 질문을 찾고, 검증 가능한 가설을 세워야 한다.**

| 스킬 | 내용 |
|:----:|:---|
| Hard Skill | • **빅데이터에 대한 이론적 지식**(방법론 습득)<br>• **분석 기술에 대한 숙련**(최적의 분석 설계) |
| Soft Skill | • **통찰력 있는 분석**(논리적 비판)<br>• **설득력있는 전달**(스토리텔링, 시각화)<br>• **다분야 간 협력**(커뮤니케이션) | 

<br>
<br>
<br>
<br>

## 02. 빅데이터 기술 및 제도

---

### 1. 빅데이터 플랫폼

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
**데이터 수집부터 저장, 처리, 분석 등 전 과정을 통합적으로 제공**하여 그 기술들을 잘 사용할 수 있도록 준비된 환경<br>
**컴퓨팅 부하, 저장 부하, 네트워크 부하들을 해소하는 기능을 한다.**
</blockquote>

#### **1-1) 빅데이터 플랫폼의 계층 구조**

1. 소프트웨어 계층: 
    - 데이터 수집 및 정제, 데이터 처리 및 분석, 사용자/서비스 관리

2. 플랫폼 계층: 
    - 데이터 및 자원의 관리, 직업, 스케줄링, 프로파일링

3. 인프라스트럭쳐 계층
    - 자원의 배치 및 관리, 저장장치 및 네트워크 관리

<img src="/assets/img/bigdata-platform.png" width="100%">

<br>
<br>

### 2. 빅데이터 처리기술

#### **2-1) 빅데이터 처리과정과 요소기술**

<img src="/assets/img/bigdata-process.png" width="100%">

1. 생성
    - DB나 파일 관리 시스템과 같은 내부 데이터가 있음
    - 외부로부터 생성된 파일이나 데이터가 있다.

2. 수집
    - 크롤링을 통해 데이터 원천으로부터 데이터를 검색하여 수집
    - **ETL**을 통해 소스 데이터로부터 추출, 변환, 적재
    - 단순한 로그 수집이 아니라 검색, 수집, 변환 과정을 모두 포함
    - **로그 수집기나, 센서 네트워크, open API** 등을 활용할 수 있다.

3. 저장(공유)
    - 저렴한 비용으로 데이터를 쉽고 빠르게 많이 저장
    - 정형 데이터뿐만 아니라 반정형, 비정형 데이터도 포함
    - **벙렬 DBMS, 하둡, NoSQL** 등 다양한 기술을 사용 가능
    - 시스템 간의 데이터 공유 가능

4. 처리
    - 분산 벙렬 및 인메모리 방식으로 실시간으로 처리
    - 대표적으로 **하둡(Hadoop)의 맵리듀스(MapReduce)**를 활용할 수 있다.

5. 분석
    - 특정 분야 및 목적의 특성에 맞는 분석 기법 선택 중요
    - **통계분석, 데이터 마이닝, 텍스트 마이닝, 기계학습** 등이 있다.

6. 시각화
    - 빅데이터 처리 및 분석 결과를 사용자에게 보여주는 기술
    - 정보 시각화 기술, 시각화 도구, 편집 기술, 실시간 자료 시각화 등으로 구성

<br>

#### **2-2) 빅데이터 수집**

1. 크롤링(Crawling) 
    - 무수히 많은 컴퓨터에 분산 저장되어 있는 문서를 수집하여 검색 대상의 색인으로 포함시키는 기술
    - 어느 부류의 기술을 얼마나 빨리 검색 대상에 포함시키는가로 우위를 결정

2. 로그 수집기
    - 조직 내부에 있는 웹 서버나 시스템의 로그를 수집하는 SW(소프트웨어)
    - 웹 로그나 트랜잭션 및 클릭 로그 등 각종 로그를 하나의 데이터로 수집

3. 센서 네트워크(Sensor Network)
    - 초경량 저전력의 많은 센서들로 구성된 유무선 네트워크
    - 통합 환경 내에서 재구성하여 처리

4. RSS Reader / Open API
    - 데이터의 생산, 공유, 참여할 수있는 환경인 웹 2.0을 구현하는 기술
    - 필요한 데이터를 프로그래밍을 통해 수집할 수 있다.

5. ETL 프로세스 
    - 추출, 변환, 적재의 약어로 다양한 원천 데이터를 취합해 추출하고 공통된 형식으로 변환하는 과정

<br>

<img src="/assets/img/ETL-Process.jpg" width="100%">

| 과정 | 설명 |
|:----:|:------------|
| 데이터 추출<br>(Extract) | • 원천 데이터로부터 적재하고자 하는 데이터를 추출 |
| 데이터 변환<br>(Transform) | • 추출한 데이터를 변환하고 균질화하며 정제<br>• 정제한 데이터를 적재하고자 하는 DW 구조에 맞게 변환 | 
| 데이터 적재<br>(Load) | • 변환된 데이터를 DW(데이터 웨어하우스)에 적재 |

<br>

#### **2-3) 빅데이터 처리**

1. **하둡(Hadoop)**
    - **분산 처리 환경에서 대용량 데이터 처리 및 분석을 지원**하는 오픈 소스 소프트웨어 프레임워크
    - 야후에서 최초로 개발했으며, 지금은 아파치 소프트웨어 재단에서 프로젝트로 관리되고 있다.

2. **스파크(Spark)**
    - 실시간 분산형 컴퓨팅 플랫폼으로 In-Memory 방식으로 처리를 하며 **하둡보다 처리속도가 빠르다.**
    - 스칼라 언어로 개발되었지만 **스칼라뿐만 아니라 Java, R, Python을 지원한다.**

3. **맵리듀스(MapReduce)**
    - 구글에서 개발한 방대한 양의 데이터를 신속하게 처리하는 프로그래밍 모델
    - 효과적인 벙렬 및 분산 처리를 지원

<br>

**✅ 맵리듀스 처리단계**

<img src="/assets/img/맵리듀스-처리.png" width="100%">

| 단계 | 내용 |
|:---:|:---|
| 1단계 | 입력 데이터를 읽고 분할한다. |
| 2단계 | 분할된 데이터를 할당해 맵 작업을 수행한 후, 그 결과인 중간 데이터를 통합 및 재분할한다. |
| 3단계 | 통합 및 재분할된 중간 데이터를 셔플(Shuffle)한다. |
| 4단계 | 셔플된 중간 데이터를 이용해 리듀스 작업을 수행한다. |
| 5단계 | 출력 데이터를 생성하고, 맵리듀스 처리를 종료한다. |

<br>
<br>

### 3. 빅데이터와 인공지능

<blockquote style="background: #E1F5Fe; color: #2e2e2ec4; padding: 1rem; margin: 1.5rem 0; border-radius: 8px;">
인공지능은 기계를 지능화하는 노력이며, 지능화란 객체가 환경에서 적절히, 그리고 예지력을 갖고 작동한다.
</blockquote>

#### **3-1) 빅데이터와 인공지능의 관계**

1. 인공지능을 위한 학습 데이터 확보
    - 딥러닝은 깊은 구조를 통해 무한한 모수 추정이 필요한 만큼 많은 양의 데이터가 필요
    - 학습의 가이드를 제공해주는 **애노테이션** 작업이 필수
    - **✅ 애노테이션**이란?
        - 데이터상의 주석 작업으로 딥러닝과 같은 학습 알고리즘이 무엇을 학습해야하는지 알려주는 표시 작업

2. 학습 데이터의 **애노테이션** 작업
    - 많은 데이터 확보 후 애노테이션을 통해 학습이 가능한 데이터로 가공하는 작업이 필요
    - 작업의 특성상 수많은 수작업이 동반되며, 이로인해 인공지능 사업은 노동집약적이라는 인식을 만듬
    - (ex: 이미지 데이터 라벨링 등)

3. 애노테이션 작업을 위한 도구로써의 인공지능
    - 인공지능 시작이 확장되며 애노테이션 작업을 전문으로 하는 기업의 수가 증가
    - 학습용 데이터에 대한 보안 및 애노테이션 결과에 대한 품질 요구수준이 높아짐
    - (ex: 데이터 라벨링 직무)

<br>

#### **3-2) 인공지능의 기술동향**

1. 기계학습 프레임워크 보급 확대(**ML Framework**)
    - **Tensorflow**는 Python 기반 딥러닝 라이브러리 여러 CPU 및 GPU와 플랫폼에서 사용 가능
    - **Keras**는 신경망 구축을 위한 단순화된 인터페이스를 가진 라이브러리며, 몇 줄의 코드만으로 딥러닝 개발 가능

2. 생성적 적대 신경망(**GAN**)
    - **GAN**는 두 개의 인공신경망으로 구성된 **딥러닝 이미지 생성 알고리즘**
    - 생성자가 가짜 사례를 생성하면 감별자가 진위를 판별하도록 구성한 후 반복
    - 주로 새로운 합성 이미지를 생성하는 분석에 많이 적용되어 왔으나, 점차 다른 분야에 응용하는 사례 증가

3. 오토인코더(**Auto-encoder**)
    - 오토인코더는 라벨이 설정되어 있지 않은 학습 데이터로부터 더욱 효율적인 코드로 표현하도록 학습하는 신경망
    - 입력 데이터의 차원을 줄여 모형을 단순화시키기 위해 활용할 수 있다.

4. 기계학습 자동화(**AutoML**)
    - 명칭 그대로 **기계학습의 전체 과정을 자동화**하는 것이다.
    - **데이터 전처리, 변수 생성, 변수 선택, 알고리즘 선택, 하이퍼파라미터 최적화 등의 기능을 수행**

<br>
<br>

### 4. 개인정보 개요

#### **4-1) 개인정보 정의**

- **살아 있는 개인에 관한 정보로서 개인을 알아볼 수 있는 정보**
- **해당 정보만으로 알아볼 수 없더라도 다른 정보와 쉽게 결합**하여 알아볼 수 있는 정보를 포함

<br>

#### **4-2) 개인정보의 판단기준**

- 생존하는 개인에 관한 정보여야 한다.
- 정보의 내용, 형태 등은 제한이 없다.
- 개인을 알아볼 수 있는 정보여야 한다.
***(다른 정보와 쉽게 결합하여 개인을 알아볼 수 있는 정보도 포함)***

<br>

#### **4-3) 빅데이터를 활용하기 위한 데이터 기본 3법**

- **개인정보보호법**
- **정보통신망** 이용촉진 및 정보보호 등에 관한 법률
- **신용정보**의 이용 및 보호에 관한 법률

<br>

#### **4-4) 202년 데이터 3법의 주요 개정 내용**
- 데이터 이용 활성화를 위한 **'가명정보'** 개념 도입 및 **데이터간 결합 근거 마련**
- 개인정보보호 관련 법률의 유사 중복 규정을 정비 및 **거버넌스 체계 효율화**
- 데이터 활용에 따른 **개인정보처리자 책임 강화**
- 다소 모호했던 **개인정보 판단기준 명확화**

<br>
<br>

### 5. 개인정보 비식별화

1. 비식별 조치
    - 개인을 식별할 수 있는 요소를 전부, 일부 삭제하거나 대체 등의 방법을 통해 개인을 알아볼 수 없도록 하는 조치

2. 개인정보 비식별화 조치 가이드라인
    - 1단계: 사전검토
    - 2단계: 비식별 조치
    - 3단계: 적정성 평가
    - 4단계: 사후 관리

3. 비식별화 방법
    - 가명처리
    - 데이터 삭제
    - 데이터 범주화

<br>
<br>

### 6. 개인정보 활용

1. 사생활 침해로 위기 발생
2. 책임원칙 훼손으로 위기 발생
3. 데이터 오용으로 위기 발생
