---
layout: post
title: "[Upstage AI Lab] 16주차 - CV-경진대회"
description: "[Upstage AI Lab] - CV 경진대회 회고"
author: "DoorNote"
date: 2025-07-11 10:00:00 +0900
#  permalink: //
categories:
    - AI | 인공지능
    - Upstage AI Lab
tags: [Deep Learning, CV, 경진대회]
use_math: true
comments: true
pin: false # 고정핀
math: true
mermaid: true
image: /assets/img/CV-썸네일.png
---

## Document Type Classification

> **Upstage AI Lab** 의 **CV 경진대회**에 대한 주요 내용과 회고록 내용
{: .prompt-tip }

---

### 1. 개요

> **Document Type Classification** 경진대회는 **문서 타입 분류를 위한 이미지 분류** 대회다.
{: .prompt-info }

**Project Overview**

- Project Duration: **2025.06.30 ~ 2025.07.10**
- Team: **3명**
- Submission: **3,140**장에 대한 **예상 문서 유형 분류** 
- Class: **17**
- Evaluation Metric: **F1 Score** macro

<br>

### 2. 주요 역할

> 본 대회는 **팀 프로젝트**로 진행되었으며, 이 글에서는 **내가 맡았던 주요 작업과 전략적 접근에 대해 기술한다.** 
> 이번 경진대회에선 **팀장**을 맡았다.
{: .prompt-info }

- **EDA**

    - **문서 유형별 이미지 특성 분석** 및 분포 확인
    - **Class Imbalance** 여부 확인
    - Class 별 **Image size** 분석
    - **Train/Test** 데이터 차이점 분석

![Class-Imbalance](/assets/img/CV-Class_Imbalance.png){: width="800" .center}
_Class Imbalance class_

<!-- ![EDA1](/assets/img/CV-EDA1.png){: width="800" .center}
![EDA2](/assets/img/CV-EDA2.png){: width="800" .center} -->


- **Data PreProcessing**  
    - **Albumentations, augraphy** 등을 사용해서 데이터 증강 **(오프라인 증강)**
    - 이미지 **회전, 잘림, 밝기/대비, 노이즈, 잉크 번짐, 그림자** 등 다양한 방법으로 증강
    - **mixup/cutmix** 등의 코드를 팀원들에게 공유
    - 데이터 증강 시 **Class Imbalance**를 고려하여, **모든 클래스의 데이터 수를 동일하게 조정**

- **실험 및 기록**
    - **WandB(Weights & Biases)**를 도입하여 **모든 실험을 체계적으로 기록 및 관리**
    - 하이퍼파라미터, 학습 곡선, 등을 실시간으로 모니터링하여 효율적인 실험 진행
    - 팀원들에게 **WandB 사용 가이드를 직접 작성 및 공유**하여 협업 효율성 증대

- **Modeling**
    - 본 프로젝트에서는 **EfficientNet, Convnext** 계열 모델을 주로 사용
    - **K-Fold**를 사용하여 모델 학습 (fold=3)
    - **Model Architecture**
        - **EfficientNetV2-L**: 대용량 모델로 성능 개선
        - **EfficientNetV2-XL**: 최고 성능을 위한 초대형 모델
        - **ConvNeXt-Base**: 기본 **ConvNeXt** 모델로 균형잡힌 성능
        - **ConvNeXt-XLarge**: 대용량 **ConvNeXt** 모델로 높은 성능
        - **ConvNeXtV2-Large**: 개선된 **ConvNeXt** 아키텍처의 대용량 모델

- **최종 제출 전략**
    - K-Fold 교차 검증으로 학습한 **각 Fold**의 모델들을 활용한 **Soft Voting 앙상블**을 적용

<br>

### 3. DataSet

> 경진대회에서 제공된 **Dataset**는 다음과 같았다.
{: .prompt-info}

- **Train**
    - 총 1,570장
    - Class: 17개
    - `train.csv` 파일에 ID와 클래스 라벨(target)이 포함
    - `meta.csv` 파일에는 클래스 번호(target)와 클래스 이름(class_name) 정보가 담겨 있음

- **Test**
    - 총 3,140장
    - `sample_submission.csv` 파일에 ID가 포함되어 있으며, 예측 결과를 제출할 때 사용
    - Test 데이터는 회전, 반전 등 다양한 변형과 훼손이 포함되어 있어, 실제 환경과 유사한 조건을 반영

<br>

### 4. 최종 결과

> 최종적으로 **10개 팀 중 9위로 대회를 마무리했다.**  
> 순위는 아쉽지만, 다양한 **모델과 증강 기법을 실험하는 과정에서 많은 것을 배울 수 있었다고 생각한다.**
{: .prompt-info}

![최종결과](/assets/img/CV-결과.png){: width="800" .center}

- **Public** Score: 0.9418
- **Private** Score: 0.9342

<!-- <br>
<br>

## 회고

> 이 섹션은 **Upstage AI Lab CV 경진대회**를 통해 경험한 **문제와 해결과정**에 대한 회고를 담았다.
{: .prompt-tip }

---

### 문제 & 해결 과정

<br>

**문제**

대회 초반 **Hold-Out** 기준으로 모델을 검증했을 때 **RMSE**가 5,000 ~ 7,000 수준으로 나왔지만 실제 제출 결과는<br> **약 3~4배** 안 좋게 나왔다. **과적합인줄 알아서 K-Fold 교차검증**을 통해 확인해 봐도 과적합 문제는 아니였다.

<br>

**해결 과정**

> **Train/Test**를 살펴보니 아래와 같이 구성 돼 있었다.

- Train Data: **2007년 ~ 2023년 6월**  
- Test Data: **2023년 7월 ~ 9월**  

<br>

즉, **완전히 분리된 시계열 구조**였으나 이를 고려하지 않고 **임의의 Hold-Out**만으로 모델을 검증한 것이 문제였다.<br>
해서 **Time-based split** 기준으로 검증셋을 **2023.05 ~ 2023.06** 설정하고 학습 및 평가를 한 결과  
**성능 차이가 대폭 감소하였다.**

<br>

### 인사이트

**아쉬웠던 점** 

> 모델링 초기엔 당연하다는 듯이 `train_test_split` 함수를 사용하여 단순 **Hold-Out** 방식으로 검증을 시작했다.  
> 이로 인해 **랜덤 분할된 검증셋**을 쓴 결과 점수는 좋았지만, 제출 점수는 훨씬 더 안 좋게 나오는 현상이 반복되었다.  
> 처음에는 이를 **과적합 문제**로 오판하고 **K-Fold 교차검증**에 많은 시간을 쏟았지만, 뒤늦게 검증 방식이 **시계열 단절**을
> 고려하지 않은 것이 문제임을 깨닫고, 변수 선택, 파라미터 튜닝 등 **다양한 실험을 시도하지 못한 점**이 아쉬웠다.

<br>

**알게 된 점** 

> 단순히 **점수가 높은 검증 방식**을 찾는 것이 중요한 것이 아니라, **데이터의 구조와 분포** 특히 시계열 문제에서는 **시간 흐름의 연속성**을 이해하고 그에 맞는 **검증 전략**을 설계해야 신뢰할 만한 평가 지표를 얻을 수 있다는 것을 배웠다.  
> 올바른 검증 방식 없이는 **하이퍼파라미터 튜닝**, **피처 선택** 등 전체 모델링 과정이 왜곡될 수 있다는 점도 실감했다. -->


